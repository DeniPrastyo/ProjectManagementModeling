{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ff4ad44",
   "metadata": {},
   "source": [
    "# **1. Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d11edbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "import itertools\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f30050b",
   "metadata": {},
   "source": [
    "# **2. Input Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2469c656",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/User/Videos/Project Management and Machine Learning/Dataset/Time/KONS\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e60952",
   "metadata": {},
   "source": [
    "# **3.Clear Excel Output** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48138bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_all_data(file):\n",
    "    workbook = load_workbook(file)\n",
    "    sheet_names = workbook.sheetnames\n",
    "    \n",
    "    if not sheet_names:\n",
    "        # If there are no sheets, create a new sheet and make it visible\n",
    "        workbook.create_sheet(\"Sheet1\")\n",
    "    else:\n",
    "        # Remove all sheets except the first one\n",
    "        for sheet_name in sheet_names[1:]:\n",
    "            workbook.remove(workbook[sheet_name])\n",
    "    \n",
    "    workbook.save(file)\n",
    "    workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e39d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_path = \"C:/Users/User/Videos/Project Management and Machine Learning/Ensemble/KONS/Time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5042241",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file1 = clear_path+\"/RESULT-ENSEMBLE-KONS-TIME.xlsx\"\n",
    "excel_file2 = clear_path+\"/PARAM-ENSEMBLE-KONS-TIME.xlsx\"\n",
    "\n",
    "clear_all_data(excel_file1)\n",
    "clear_all_data(excel_file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705100ee",
   "metadata": {},
   "source": [
    "# **3. Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0e2eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlendingEnsemble():\n",
    "    def __init__(self, alpha=0.1, alpha_r=0.1, degree=1):\n",
    "        self.models = []\n",
    "        self.blender = None\n",
    "        self.alpha = alpha\n",
    "        self.alpha_r = alpha_r\n",
    "        self.degree = degree\n",
    "\n",
    "    def get_models(self):\n",
    "        models = []\n",
    "        models.append(('Lasso', Lasso(alpha = self.alpha)))\n",
    "        models.append(('Ridge', Ridge(alpha = self.alpha_r)))\n",
    "        models.append(('Poly', make_pipeline(PolynomialFeatures(degree = self.degree),LinearRegression())))\n",
    "        return models\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.models = self.get_models()\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.33, random_state=1)\n",
    "\n",
    "        meta_X = []\n",
    "        for name, model in self.models:            \n",
    "            model.fit(X_train, y_train)\n",
    "            yhat = model.predict(X_val)\n",
    "            yhat = yhat.reshape(-1, 1)\n",
    "            meta_X.append(yhat)\n",
    "            \n",
    "        meta_X = np.hstack(meta_X)\n",
    "\n",
    "        blender = make_pipeline(PolynomialFeatures(),LinearRegression())\n",
    "\n",
    "        blender.fit(meta_X, y_val)\n",
    "        self.blender = blender\n",
    "\n",
    "        return self.blender\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        meta_X = []\n",
    "        for _, model in self.models:\n",
    "            yhat = model.predict(X_test)\n",
    "            yhat = yhat.reshape(-1, 1)\n",
    "            meta_X.append(yhat)\n",
    "\n",
    "        meta_X = np.hstack(meta_X)\n",
    "\n",
    "        return self.blender.predict(meta_X)\n",
    "\n",
    "    def evaluate_r2(self, y_true, y_pred):\n",
    "        return r2_score(y_true, y_pred)\n",
    "\n",
    "    def evaluate_rmse(self, y_true, y_pred):\n",
    "        return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    def __call__(self, X):\n",
    "        return self.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e4f318d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleRegressor:\n",
    "    def __init__(self, data_source_file, result_file,params_file):\n",
    "        self.data_source_file = data_source_file\n",
    "        self.result_file = result_file\n",
    "        self.params_file = params_file\n",
    "        self.models = {\n",
    "            'XGBoost': xgb.XGBRegressor,\n",
    "            'RandomForest': RandomForestRegressor\n",
    "        }\n",
    "    \n",
    "\n",
    "    def train_and_predict(self, sheet, model_name='Blending', param_grid=None):\n",
    "        # Splitting features and label\n",
    "        data = pd.read_excel(self.data_source_file, sheet_name=sheet)\n",
    "        X = data.drop(columns='Earned Value')\n",
    "        y = data['Earned Value']\n",
    "\n",
    "        # Splitting data into training and testing sets\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=58)\n",
    "        x_train = x_train.sort_index(ascending=True)\n",
    "        y_train = y_train.sort_index(ascending=True)\n",
    "        x_test = x_test.sort_index(ascending=True)\n",
    "        y_test = y_test.sort_index(ascending=True)\n",
    "\n",
    "        # Model selection\n",
    "        model_class = self.models.get(model_name)\n",
    "        if model_class is None:\n",
    "            raise ValueError(f\"Invalid model name: {model_name}\")\n",
    "\n",
    "        # Parameter tuning\n",
    "        best_params, results = self.tune_parameters(model_class, x_train, y_train, param_grid)\n",
    "\n",
    "        # Train the model with the best parameters\n",
    "        model = model_class(**best_params)\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        # Predict on the test set\n",
    "        x_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        ev_pred = model.predict(x_test)\n",
    "\n",
    "        # Create a DataFrame with predictions\n",
    "        perform = pd.DataFrame({'AT':x_test.iloc[:,0].values,'Planned Value':x_test.iloc[:,1].values,\n",
    "                                'Actual': y_test.values, 'EV_Pred': ev_pred, 'Model': model_name})\n",
    "        results ['Model']=model_name\n",
    "        results ['Method'] = \"ensemble\"\n",
    "        results ['Subwork'] = sheet \n",
    "        results ['Work'] = \"KONS\"\n",
    "        results ['Process'] = \"Time\"\n",
    "        \n",
    "        perform ['Method'] = \"ensemble\"\n",
    "        perform ['Subwork'] = sheet \n",
    "        perform ['Work'] = \"KONS\"\n",
    "        perform ['Process'] = \"Time\"\n",
    "        # Save the results to Excel files\n",
    "        self.to_excel(perform, self.result_file, sheet)\n",
    "        self.to_excel(results, self.params_file, sheet)\n",
    "\n",
    "    def tune_parameters(self, model_class, X, y, param_grid=None):\n",
    "        if param_grid is None:\n",
    "            param_grid = {}  \n",
    "\n",
    "        # Grid search to find the best parameters\n",
    "        best_params = None\n",
    "        best_score = float('inf')\n",
    "        results = []\n",
    "\n",
    "        for params in self.grid_search(param_grid):\n",
    "            model = model_class(**params)\n",
    "            model.fit(X, y)\n",
    "            y_pred = model.predict(X)\n",
    "            r2 = self.evaluate_r2(y, y_pred)\n",
    "            rmse = self.evaluate_rmse(y, y_pred)\n",
    "\n",
    "            results.append({**params, 'R2': r2, 'RMSE': rmse})\n",
    "\n",
    "            if rmse < best_score:\n",
    "                best_score = rmse\n",
    "                best_params = params\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "        return best_params, results_df\n",
    "\n",
    "    @staticmethod\n",
    "    def grid_search(param_grid):\n",
    "        keys, values = zip(*param_grid.items())\n",
    "        for combination in itertools.product(*values):\n",
    "            yield dict(zip(keys, combination))\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate_r2(y_true, y_pred):\n",
    "        return r2_score(y_true, y_pred)\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate_rmse(y_true, y_pred):\n",
    "        return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    @staticmethod\n",
    "    def to_excel(df, file, sheet_name):\n",
    "        try:\n",
    "            book = load_workbook(file)\n",
    "            writer = pd.ExcelWriter(file, engine='openpyxl')\n",
    "            writer.book = book\n",
    "            writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "            if sheet_name in writer.sheets:\n",
    "                sheet = writer.sheets[sheet_name]\n",
    "                last_row = sheet.max_row\n",
    "            else:\n",
    "                last_row = 0\n",
    "\n",
    "            if last_row < 1:\n",
    "                df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            else:\n",
    "                df.to_excel(writer, sheet_name=sheet_name, index=False, header=True, startrow=last_row)\n",
    "\n",
    "            writer.save()\n",
    "        except FileNotFoundError:\n",
    "            df.to_excel(file, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29033c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blending_ensemble (x):\n",
    "    Sheet = x\n",
    "    Data = pd.read_excel (path+\"/Dataset.xlsx\",sheet_name = Sheet )\n",
    "    X = Data.drop (columns = 'Earned Value')\n",
    "    y = Data.drop (columns = X.columns)\n",
    "\n",
    "    #Splitting Data Training and Testing\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y ,train_size = 0.8,random_state = 58)\n",
    "    x_train = x_train.sort_index(ascending=True)\n",
    "    y_train = y_train.sort_index(ascending=True)\n",
    "    x_test = x_test.sort_index(ascending=True)\n",
    "    y_test = y_test.sort_index(ascending=True)\n",
    "\n",
    "    Val =[]\n",
    "    blg_model = BlendingEnsemble()\n",
    "    for alpha in np.arange (0.025,0.75,0.25):\n",
    "        for alpha_r in np.arange(0.25,0.76,0.25) :\n",
    "            for degree in range (2,5) : \n",
    "                    blg_model.alpha = alpha\n",
    "                    blg_model.alpha_r = alpha_r\n",
    "                    blg_model.degree = degree\n",
    "                        ##create the model \n",
    "\n",
    "                    blg_model.fit (x_train,y_train)\n",
    "                        #######Train################\n",
    "                    y_train_Pred = blg_model.predict (x_train)\n",
    "                    y_train_Pred = pd.DataFrame({'Y_train_Pred':y_train_Pred.ravel()})\n",
    "\n",
    "                    y_train.reset_index(drop=True,inplace=True)\n",
    "                    y_train_Pred.reset_index(drop = True,inplace=True)\n",
    "\n",
    "                    Compare_train = pd.concat([y_train,y_train_Pred],axis=1)\n",
    "\n",
    "                    R2_train = r2_score (Compare_train['Earned Value'],Compare_train['Y_train_Pred'])\n",
    "                    RMSE_train = np.sqrt(mean_squared_error(Compare_train['Earned Value'],Compare_train['Y_train_Pred']))\n",
    "\n",
    "                        ######Prediction############\n",
    "                    y_pred = blg_model.predict(x_test)\n",
    "                    y_pred = pd.DataFrame({'Y_pred':y_pred.ravel()})\n",
    "                        #reset index for handling NaN\n",
    "                    y_pred.reset_index(drop=True, inplace=True)\n",
    "                    y_test.reset_index(drop=True, inplace=True)\n",
    "                        #Comparing prediction and label data\n",
    "                    Compare = pd.concat([y_test,y_pred],axis =1)\n",
    "                        #Performance\n",
    "                    R2 = r2_score (Compare['Earned Value'],Compare['Y_pred'])\n",
    "                    RMSE = np.sqrt(mean_squared_error(Compare['Earned Value'],Compare['Y_pred']))\n",
    "                    Gap = abs (RMSE_train - RMSE)\n",
    "                    Blending = \"Blending\"\n",
    "                    Val.append([alpha, alpha_r,degree, R2, RMSE,Blending ])\n",
    "                    Value=pd.DataFrame(Val,columns=[\"alpha\",\"alpha_r\",\"degree\",\"R2\",\"RMSE\",\"Model\"])\n",
    "                    Value ['Method'] = \"ensemble\"\n",
    "                    Value ['Subwork'] = Sheet \n",
    "                    Value ['Work'] = \"KONS\"\n",
    "                    Value ['Process'] = \"Time\"\n",
    "\n",
    "\n",
    "    param = Value.sort_values(by = ['RMSE'],ascending = True )\n",
    "    alpha_param = param['alpha'].iloc[0]\n",
    "    alpha_r_param = param['alpha_r'].iloc[0]\n",
    "    degree_param = param['degree'].iloc[0]\n",
    "\n",
    "\n",
    "    blg_param = BlendingEnsemble(alpha= alpha_param,\n",
    "                                      alpha_r = alpha_r_param, \n",
    "                                      degree = degree_param)\n",
    "    blg_param.fit(x_train,y_train)\n",
    "    EV_pred = blg_param.predict(x_test)\n",
    "    EV_pred = pd.DataFrame({'EV_Pred':EV_pred.ravel()})\n",
    "\n",
    "    EV_pred.reset_index(drop=True, inplace=True)\n",
    "    y_test.reset_index(drop=True, inplace=True)\n",
    "    x_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    Perform = pd.concat([x_test,y_test,EV_pred],axis=1)\n",
    "    Perform ['Model'] = Blending\n",
    "    Perform ['Method'] = \"ensemble\"\n",
    "    Perform ['Subwork'] = Sheet \n",
    "    Perform ['Work'] = \"KONS\"\n",
    "    Perform ['Process'] = \"Time\"\n",
    "    \n",
    "    def to_excel(df, file, sheet_name):\n",
    "        try:\n",
    "            book = load_workbook(file)\n",
    "            writer = pd.ExcelWriter(file, engine='openpyxl')\n",
    "            writer.book = book\n",
    "            writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "            if sheet_name in writer.sheets:\n",
    "                sheet = writer.sheets[sheet_name]\n",
    "                last_row = sheet.max_row\n",
    "            else:\n",
    "                last_row = 0\n",
    "\n",
    "            if last_row < 1:\n",
    "                df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            else:\n",
    "                df.to_excel(writer, sheet_name=sheet_name, index=False, header=True, startrow=last_row)\n",
    "\n",
    "            writer.save()\n",
    "        except FileNotFoundError:\n",
    "            df.to_excel(file, sheet_name=sheet_name, index=False)\n",
    "    \n",
    "    #Converting Value Adjusting All Parameter to Excel\n",
    "    Adjusting = to_excel(Value,\"PARAM-ENSEMBLE-KONS-TIME.xlsx\",x)\n",
    "    Prediction = to_excel(Perform,\"RESULT-ENSEMBLE-KONS-TIME.xlsx\",x)\n",
    "    \n",
    "    return Adjusting, Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fa3702",
   "metadata": {},
   "source": [
    "# **Running K1B1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de84d78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source_file = path+\"/Dataset.xlsx\"\n",
    "result_file = \"RESULT-ENSEMBLE-KONS-TIME.xlsx\"\n",
    "params_file = \"PARAM-ENSEMBLE-KONS-TIME.xlsx\"\n",
    "\n",
    "ensemble = EnsembleRegressor(data_source_file, result_file,params_file )\n",
    "\n",
    "\n",
    "param_grid_xg = { 'n_estimators': [50, 100, 200],'max_depth': [3, 5, 7],'learning_rate': [0.1, 0.05, 0.01] }\n",
    "param_grid_rf = { 'n_estimators': [50, 100, 200],'max_depth': [3, 5, 7],'min_samples_split': [0.1, 0.05, 0.01] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5add3186",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.train_and_predict('K1B1', model_name='XGBoost', param_grid=param_grid_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34bb5c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.train_and_predict('K1B1', model_name='RandomForest', param_grid=param_grid_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8eda6e27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blending_ensemble ('K1B1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216eaae3",
   "metadata": {},
   "source": [
    "# **Running K1B2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59cb01ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.train_and_predict('K1B2', model_name='XGBoost', param_grid=param_grid_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c17ea524",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.train_and_predict('K1B2', model_name='RandomForest', param_grid=param_grid_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44b578c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blending_ensemble ('K1B2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33fcc91",
   "metadata": {},
   "source": [
    "# **Running K2B1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "414e9751",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.train_and_predict('K2B1', model_name='XGBoost', param_grid=param_grid_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b3eb502",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.train_and_predict('K2B1', model_name='RandomForest', param_grid=param_grid_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f2dc3d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blending_ensemble ('K2B1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a3bd95",
   "metadata": {},
   "source": [
    "# **Running K2B2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7381eb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.train_and_predict('K2B2', model_name='XGBoost', param_grid=param_grid_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df75414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.train_and_predict('K2B2', model_name='RandomForest', param_grid=param_grid_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "537ccd53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blending_ensemble ('K2B2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0091ef7",
   "metadata": {},
   "source": [
    "# **Running K3B1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b045280",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.train_and_predict('K3B1', model_name='XGBoost', param_grid=param_grid_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9d7ba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.train_and_predict('K3B1', model_name='RandomForest', param_grid=param_grid_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "941444c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blending_ensemble ('K3B1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e0dcf6",
   "metadata": {},
   "source": [
    "# **Running K3B2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abafe6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.train_and_predict('K3B2', model_name='XGBoost', param_grid=param_grid_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aef50b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.train_and_predict('K3B2', model_name='RandomForest', param_grid=param_grid_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c360ea39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blending_ensemble ('K3B2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714d47be",
   "metadata": {},
   "source": [
    "# **Running KUM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c51bf765",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.train_and_predict('Kum', model_name='XGBoost', param_grid=param_grid_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "466d8a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.train_and_predict('Kum', model_name='RandomForest', param_grid=param_grid_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "497b847d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blending_ensemble ('Kum')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
